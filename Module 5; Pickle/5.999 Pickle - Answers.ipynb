{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4005a29",
   "metadata": {},
   "source": [
    "# Module 5: Pickle\n",
    "\n",
    "### Introduction\n",
    "There are many different file types used in the data world. Main examples are .csv, .json and .xml, which are are easy to read and/or write, and are used extensively in multiple programming languages. However, sometimes you want to save a Python data object directly, such as a dictionary, list, tuple or even a fully trained machine learning algorithms created in Python. This is where the *pickle* module comes in.\n",
    "\n",
    "This module will give you an in-depth look on how to best use the *pickle* module to save and load Python data objects. The outline is:\n",
    "1. Pickle files basics\n",
    "2. The Python *pickle* module \n",
    "3. speed comparison of pickle files and other ways of saving data objects\n",
    "4. saving and loading fully trained machine learning algorithm \n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages needed for section 1 to 3\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab55d06",
   "metadata": {},
   "source": [
    "# Section 1: Pickle files\n",
    "\n",
    "Pickle is a very useful Python library. Pickle can be used to serialize Python object structures. Any object in Python can be pickled so that it can be saved on disk. So it's very specific to Python. This process of serializing Python object structures refers to the process of converting an object in the memory to a byte stream that can be stored as a binary file on disk. When we load it back to a Python program, this binary file can be de-serialized back to a Python object.\n",
    "\n",
    "Besides the fact that we can store Python objects, there is another advantage; its speed. Later in the module we'll focus a bit more on the speed of pickle, but let's look at an example below to get an idea.\n",
    "\n",
    "First, we'll have to create an object that we can store. Then, we'll look at the speed differences between Pandas and Pickle in storing this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56619b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to store.\n",
    "\n",
    "np.random.seed = 0\n",
    "df_size = 1_000_000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': np.random.rand(df_size),\n",
    "    'b': np.random.rand(df_size),\n",
    "    'c': np.random.rand(df_size),\n",
    "    'd': np.random.rand(df_size),\n",
    "    'e': np.random.rand(df_size)\n",
    "})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e89959",
   "metadata": {},
   "source": [
    "Let's store the Pandas DataFrame as a .csv file using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eba19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Save the Pandas DataFrame as a .csv file.\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44afd6",
   "metadata": {},
   "source": [
    "Let's store the Pandas DataFrame as a pickle file using the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Save the Pandas DataFrame as a pickle file.\n",
    "with open('dataframe.pickle', mode='wb') as file:\n",
    "    pickle.dump(df, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f5615",
   "metadata": {},
   "source": [
    "When you look at the time differences, there should be quite a difference. Pickle objects are very much faster to work with. Now that we have seen an example, we can take a look at the pickle library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649226e2",
   "metadata": {},
   "source": [
    "In the folder you are currently working in, there are some pickled files saved already. Pickled files are saved as a binary file. Let's print all the files that are in the current folder to see them.\n",
    "\n",
    "##### ASSIGNMENT 1: print all pickle files in the directory of the notebook\n",
    "*Hint: use the skills learned in the file-system operations module*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ba9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pickle_files = []\n",
    "\n",
    "#### ADD YOUR CODE HERE ####\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.pickle'):\n",
    "        list_of_pickle_files.append(file)\n",
    "#### STOP ADDING CODE HERE ####\n",
    "\n",
    "print(list_of_pickle_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99df01",
   "metadata": {},
   "source": [
    "### **Theory: which file extensions are used for pickle file?**\n",
    "There are three pickle files found. They can be easily recognized by their *.pickle* extension. However, this is not the only used extension for pickle files. \n",
    "\n",
    "For instance, in the [Python 2 documentation](https://docs.python.org/2/library/pickle.html#example) *.pkl* is used as an extension.\n",
    "Other examples online might include *.p* as an extension\n",
    "\n",
    "##### ASSIGNMENT 2: print the contents of the pickle files with .read(). Also use the 'open' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_of_pickle_files:\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "    with open(file, mode='rb') as pickle_file:\n",
    "        print(f'The contents of {file} are: ')\n",
    "        print(pickle_file.read())\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3171af",
   "metadata": {},
   "source": [
    "Most likely, you cannot make any sense of the file contents. This is because pickle files are Python Objects that are serialized into a byte stream. The printed content shows the actual bytes.\n",
    "\n",
    "When you are unsure with what kind of data object you are working with, it is often a good choice to check the data type with 'type()'. \n",
    "\n",
    "##### ASSIGNMENT 3: print the file type of each pickled file with type() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_of_pickle_files:\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "    with open(file, mode='rb') as pickle_file:\n",
    "        print(f'The object type of contents of {file} are: {type(pickle_file.read())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6ced8",
   "metadata": {},
   "source": [
    "### **Theory - why use pickle?**\n",
    "Compared to other file types, it might be unclear at this point why we want to use pickle at all. Binary files aren't easy to read or use in general. So wouldn't it be more convenient to save data as a more generic file types such as XML, JSON or CSV?\n",
    "\n",
    "The answer is: it depends on what type of information you want to save and/or transfer. Pickle is ment as a convenient file type to transfer **Python objects** specifically between different systems, environments or pieces of Python code. It is the fastest and most efficient way to transport practically any(!) Python object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51011540",
   "metadata": {},
   "source": [
    "# Section 2: The Python *pickle* module\n",
    "The *pickle* module is part of the standard library that comes with Python. As mentioned earlier, it is used to easily serialize and deserialize Python objects. Let's take a look at the most important methods the module has to offer!\n",
    "\n",
    "For more information, please refer to the [official pickle documentation](https://docs.python.org/3/library/pickle.html)\n",
    "\n",
    "Let's explore the functionality in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e21ef2",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 4: create a Python object and save it as a pickle file with the dump() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10139c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE\n",
    "a_list = ['hi', 'I', 'am', 'a', 'list']\n",
    "\n",
    "# Then open a new file with the built-in open() function\n",
    "with open('pickled_list.pickle', mode='wb') as file:\n",
    "    pickle.dump(a_list, file)  # save it as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee844ed",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 5:  open the object you just created with load() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE\n",
    "\n",
    "# Then open a new file with the built-in open() function\n",
    "with open('pickled_list.pickle', mode='rb') as file:\n",
    "    loaded_list = pickle.load(file)  # save it as a pickle file\n",
    "print(loaded_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae87268",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 6: load the pickle files that were already present in the folder and determine what kind of Python objects they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5952b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE\n",
    "for pickle_file in list_of_pickle_files:\n",
    "    with open(pickle_file, mode='rb') as file:\n",
    "        loaded_file = pickle.load(file)  # save it as a pickle file\n",
    "    print(loaded_file)\n",
    "    print(type(loaded_file))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2ad78",
   "metadata": {},
   "source": [
    "# Section 3: speed comparison\n",
    "\n",
    "### **Theory - speed and file size of pickle files**\n",
    "As a Data Engineer, you often want the most efficient solution to the challenges that appear during your work. When working with small datasets, different approaches might seem interchangeable. However, working with larger datasets, you will notice differences in the runtime speed of code.\n",
    "\n",
    "In this section, we will explore how fast writing and reading pickle files are when working with tabular data compared to using .csv files. The pandas libary will be used to create a large dummy dataset, save it to disk and load it again. Since the focus of this module is Pickle, there will not be in-depth info of pandas, but it is always possible to check out the [Pandas Documentation](https://pandas.pydata.org/docs/). \n",
    "\n",
    "Furthermore, we will use a builtin magic function of jupyter called *%%time* that will show the time it took to run a certain cell. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6c79e",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 7: create a dummy dataset of 5 columns and 2 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "df_size = 5_000_000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': np.random.rand(df_size),\n",
    "    'b': np.random.rand(df_size),\n",
    "    'c': np.random.rand(df_size),\n",
    "    'd': np.random.rand(df_size),\n",
    "    'e': np.random.rand(df_size)\n",
    "})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b09c93",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 8: save the DataFrame as a .csv file using the .to_csv() function of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### ADD YOUR CODE HERE ####\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da63b9c",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 9: load the created .csv file as a DataFrame using the pandas.read_csv() funcion of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### ADD YOUR CODE HERE ####\n",
    "df_from_csv = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ebb0c",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 10: now save the original DataFrame we created as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22059f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### ADD YOUR CODE HERE ####\n",
    "with open('dataframe.pickle', mode='wb') as file:\n",
    "    pickle.dump(df, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498ff1c",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 11: now deserialize pickle file containing the serialized DataFrame into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### ADD YOUR CODE HERE ####\n",
    "with open('dataframe.pickle', mode='rb') as file:\n",
    "    deserialized_df = pickle.load(file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61e883",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 12: Now print the file size of both the csv file and the pickle file you created.\n",
    "\n",
    "*Hint: the OS library has something for this called getsize()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE ####\n",
    "size_of_pickle = os.path.getsize('dataframe.pickle') / 1_000_000\n",
    "size_of_csv = os.path.getsize('data.csv') / 1_000_000\n",
    "\n",
    "print(f'The size of the pickle file is {size_of_pickle} bytes')\n",
    "print(f'The size of the csv file is {size_of_csv} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789816fa",
   "metadata": {},
   "source": [
    "### **Theory - speed and file size of pickle files**\n",
    "As you can see Pickle is way more efficient to use as a temporary storage than .csv when it comes to tabular data.\n",
    "* it is much faster to read/write pickle files than csv files\n",
    "* the file size is also smaller for pickle files compared to csv files\n",
    "\n",
    "However, there are also downsides. Pickle creates files unreadable for humans, and cannot be loaded into programs like Excel. Therefore, always make sure if pickle is the right fit for the job!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cdd20",
   "metadata": {},
   "source": [
    "# Section 4: pickle and machine learning algorithms\n",
    "In this final section, we are going to save a fully trained machine learning model into a pickle file. As already stated, almost all Python objects can be stored as pickle, and this includes ML models. This is arguably the most powerful usage of Pickle for a Data Engineer when working with ML models.\n",
    "\n",
    "Since the focus of this Module is not on the creation or training of a ML model, a cell with all code required to do this is given below. Simply run the cell to load the correct data and train a model.\n",
    "\n",
    "The data we use is from the famous [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris), which is often used to showcase classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f75364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra libraries needed for this section\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601c32f",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 13: run the following few cells to load and explore the data, and subsequently train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# turn data into DataFrame\n",
    "df_iris = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                       columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "# Add species column\n",
    "df_iris['species'] = df_iris['target'].map({\n",
    "    0:'setosa',\n",
    "    1:'versicolor',\n",
    "    2: 'virginica'\n",
    "})\n",
    "\n",
    "# Show top rows of DataFrame\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa778c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the petal length and petal width\n",
    "df_iris.plot.scatter(\n",
    "    x='petal length (cm)',\n",
    "    y='petal width (cm)',\n",
    "    c='target',\n",
    "    colormap='viridis',\n",
    "    figsize=(12,8))\n",
    "\n",
    "plt.xlabel(\"petal length (cm)\", size=12)\n",
    "plt.ylabel(\"petal width (cm)\", size=12)\n",
    "plt.title('Iris petals (color indicates class)', size=16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72319d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS TO CHANGE\n",
    "input_columns = ['petal length (cm)','petal width (cm)']\n",
    "test_size = 0.5\n",
    "random_state = 42\n",
    "model = LogisticRegression()\n",
    "model_name = 'LR_with_petaldata'\n",
    "\n",
    "\n",
    "# Create input X, and target y to train the model with \n",
    "X = df_iris[input_columns]  # only use petal length and width\n",
    "X = X.to_numpy()  # converting into numpy array\n",
    "y = iris['target']\n",
    "\n",
    "# Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=42)\n",
    "\n",
    "# Fit the model based on chosen parameters\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3d1ab",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 14: save the fitted model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE ####\n",
    "path_to_savefile = model_name + '.pickle'\n",
    "\n",
    "with open(path_to_savefile, mode='wb') as file:\n",
    "    pickle.dump(model, file)  # save it as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256af67d",
   "metadata": {},
   "source": [
    "##### ASSIGNMENT 15: load the fitted model and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE ####\n",
    "path_to_model = 'LR_with_petaldata.pickle'\n",
    "with open(path_to_model, mode='rb') as file:\n",
    "    loaded_model = pickle.load(file)  # save it as a pickle file\n",
    "\n",
    "training_prediction = loaded_model.predict(X_train)\n",
    "test_prediction = loaded_model.predict(X_test)\n",
    "#### STOP ADDING YOUR CODE HERE ####\n",
    "\n",
    "\n",
    "# Precision Recall scores\n",
    "print(\"Precision, Recall, Confusion matrix, in training\\n\")\n",
    "print(metrics.classification_report(y_train, training_prediction, digits=3))\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confuson matrix')\n",
    "print(metrics.confusion_matrix(y_train, training_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078e470",
   "metadata": {},
   "source": [
    "##### (OPTIONAL) ASSIGNMENT 16\n",
    "* fit another Logistic Regression model with diffent input columns (sepal data instead of petal)\n",
    "* save the model under a different name\n",
    "* load both models and compare metrics (doublecheck you are using the right X_train and X_test for each model when predicting)\n",
    "\n",
    "Which model performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a620fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS TO CHANGE\n",
    "input_columns = ['sepal length (cm)','sepal width (cm)']\n",
    "test_size = 0.5\n",
    "random_state = 42\n",
    "model = LogisticRegression()\n",
    "model_name = 'LR_with_sepaldata'\n",
    "\n",
    "\n",
    "# Create input X, and target y to train the model with \n",
    "X = df_iris[input_columns]  # only use petal length and width\n",
    "X = X.to_numpy()  # converting into numpy array\n",
    "y = iris['target']\n",
    "\n",
    "# Splitting into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=42)\n",
    "\n",
    "# Fit the model based on chosen parameters\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "training_prediction = model.predict(X_train)\n",
    "\n",
    "test_prediction = model.predict(X_test)\n",
    "\n",
    "print(\"Precision, Recall, Confusion matrix, in training\\n\")\n",
    "\n",
    "# Precision Recall scores\n",
    "print(metrics.classification_report(y_train, training_prediction, digits=3))\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confuson matrix')\n",
    "print(metrics.confusion_matrix(y_train, training_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225ad92",
   "metadata": {},
   "source": [
    "## **THEORY - Pickle for Machine Learning models**\n",
    "As you can see, saving different models as different pickle files is done easily. This can be of great help to a Data Engineer working with ML models.\n",
    "\n",
    " For example, it makes model comparison all trained with different parameters more organized and efficient. \n",
    " \n",
    " Furthermore, it can help productionalize models: train multiple models and compare them in a development environment and only transfer the pickle file of the best performing model to the production environment.\n",
    "\n",
    " Congratulations on completing this module!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15b20538a962554200a580dbac694884175b6fc3c353c551da694757f0ccb282"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
